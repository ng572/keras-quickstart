{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "692ffb82",
   "metadata": {},
   "source": [
    "## CIFAR-10\n",
    "we are going to do some classification work with the CIFAR-10 dataset that comes with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "522a8c0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data() # documentation suggests two tuples format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a138a1da",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "we are going to normalize the features range from (0, 255) to (0, 1)\\\n",
    "for each color / channel of the image\n",
    "\n",
    "## Validation data\n",
    "\n",
    "will be used to see when to conduct early stopping,\\\n",
    "we're going to use 10% of the data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "185d969e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34bb862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train/255, x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b19262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train) # one-hot encoding the labels\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a8fb716",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid = x_train[5000:], x_train[:5000]\n",
    "y_train, y_valid = y_train[5000:], y_train[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c352307",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "the model should go from wide to narrow, and from thin to thick\\\n",
    "such is the way how things go in general for CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "625be7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 128)         32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 256)         131328    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 512)         524800    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 702,826\n",
      "Trainable params: 702,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Conv2D, MaxPool2D, Activation, Flatten\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.Input(shape=(32, 32, 3)))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=2, strides=1, padding='same', activation='relu')) # out = 16\n",
    "model.add(MaxPool2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=2, strides=1, padding='same', activation='relu')) # out = 8\n",
    "model.add(MaxPool2D(pool_size=2))\n",
    "model.add(Conv2D(filters=128, kernel_size=2, strides=1, padding='same', activation='relu')) # out = 4\n",
    "model.add(MaxPool2D(pool_size=2))\n",
    "model.add(Conv2D(filters=256, kernel_size=2, strides=1, padding='same', activation='relu')) # out = 2\n",
    "model.add(MaxPool2D(pool_size=2))\n",
    "model.add(Conv2D(filters=512, kernel_size=2, strides=1, padding='same', activation='relu')) # out = 1\n",
    "model.add(MaxPool2D(pool_size=2))\n",
    "\n",
    "# not sure if we have to reshape the data here, let's just try running it first\n",
    "# turns out we have to add a Flatten layer\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10)) # CIFAR 10 means 10 categories\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# sparse_categorical_crossentropy didn't work here, not sure why\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c282c9e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1407/1407 [==============================] - 42s 29ms/step - loss: 1.4986 - accuracy: 0.4443 - val_loss: 1.1312 - val_accuracy: 0.5950\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.13117, saving model to cifar-10.best.valid.accuracy\n",
      "INFO:tensorflow:Assets written to: cifar-10.best.valid.accuracy\\assets\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 40s 28ms/step - loss: 1.0875 - accuracy: 0.6099 - val_loss: 1.0312 - val_accuracy: 0.6318\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.13117 to 1.03121, saving model to cifar-10.best.valid.accuracy\n",
      "INFO:tensorflow:Assets written to: cifar-10.best.valid.accuracy\\assets\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.9036 - accuracy: 0.6756 - val_loss: 0.8765 - val_accuracy: 0.6956\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.03121 to 0.87649, saving model to cifar-10.best.valid.accuracy\n",
      "INFO:tensorflow:Assets written to: cifar-10.best.valid.accuracy\\assets\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.7806 - accuracy: 0.7230 - val_loss: 1.0031 - val_accuracy: 0.6604\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.87649\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 43s 30ms/step - loss: 0.6740 - accuracy: 0.7604 - val_loss: 0.8151 - val_accuracy: 0.7196\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.87649 to 0.81511, saving model to cifar-10.best.valid.accuracy\n",
      "INFO:tensorflow:Assets written to: cifar-10.best.valid.accuracy\\assets\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 39s 28ms/step - loss: 0.5833 - accuracy: 0.7912 - val_loss: 0.8214 - val_accuracy: 0.7194\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.81511\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 42s 30ms/step - loss: 0.4995 - accuracy: 0.8232 - val_loss: 0.7681 - val_accuracy: 0.7440\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.81511 to 0.76808, saving model to cifar-10.best.valid.accuracy\n",
      "INFO:tensorflow:Assets written to: cifar-10.best.valid.accuracy\\assets\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 42s 30ms/step - loss: 0.4235 - accuracy: 0.8500 - val_loss: 0.8938 - val_accuracy: 0.7150\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.76808\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 43s 31ms/step - loss: 0.3557 - accuracy: 0.8713 - val_loss: 0.8941 - val_accuracy: 0.7382\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.76808\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 42s 30ms/step - loss: 0.2959 - accuracy: 0.8947 - val_loss: 0.9110 - val_accuracy: 0.7418\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.76808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x229fa975fa0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath='cifar-10.best.valid.accuracy', save_best_only=True, verbose=1)\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_valid, y_valid), callbacks=checkpointer, shuffle=True) # having a mini-batch reduces the stochasticity and increase performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d31708bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.8028 - accuracy: 0.7318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8028061389923096, 0.7318000197410583]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(filepath=\"cifar-10.best.valid.accuracy\")\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56752d8f",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "the test accuracy is 73%, which is reasonable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
